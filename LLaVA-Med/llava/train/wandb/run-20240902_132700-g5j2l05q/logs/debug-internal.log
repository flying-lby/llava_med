2024-09-02 13:27:00,072 INFO    StreamThr :1886340 [internal.py:wandb_internal():85] W&B internal server running at pid: 1886340, started at: 2024-09-02 13:27:00.071271
2024-09-02 13:27:00,076 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: status
2024-09-02 13:27:00,077 INFO    WriterThread:1886340 [datastore.py:open_for_write():87] open: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/run-g5j2l05q.wandb
2024-09-02 13:27:00,078 DEBUG   SenderThread:1886340 [sender.py:send():391] send: header
2024-09-02 13:27:00,080 DEBUG   SenderThread:1886340 [sender.py:send():391] send: run
2024-09-02 13:27:00,950 INFO    SenderThread:1886340 [dir_watcher.py:__init__():211] watching files in: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files
2024-09-02 13:27:00,950 INFO    SenderThread:1886340 [sender.py:_start_run_threads():1200] run started: g5j2l05q with start time 1725254820.071183
2024-09-02 13:27:00,975 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: check_version
2024-09-02 13:27:00,975 DEBUG   SenderThread:1886340 [sender.py:send_request():418] send_request: check_version
2024-09-02 13:27:01,770 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: run_start
2024-09-02 13:27:01,784 DEBUG   HandlerThread:1886340 [system_info.py:__init__():26] System info init
2024-09-02 13:27:01,784 DEBUG   HandlerThread:1886340 [system_info.py:__init__():41] System info init done
2024-09-02 13:27:01,784 INFO    HandlerThread:1886340 [system_monitor.py:start():194] Starting system monitor
2024-09-02 13:27:01,785 INFO    SystemMonitor:1886340 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-09-02 13:27:01,785 INFO    HandlerThread:1886340 [system_monitor.py:probe():214] Collecting system info
2024-09-02 13:27:01,786 INFO    SystemMonitor:1886340 [interfaces.py:start():188] Started cpu monitoring
2024-09-02 13:27:01,787 INFO    SystemMonitor:1886340 [interfaces.py:start():188] Started disk monitoring
2024-09-02 13:27:01,787 INFO    SystemMonitor:1886340 [interfaces.py:start():188] Started gpu monitoring
2024-09-02 13:27:01,790 INFO    SystemMonitor:1886340 [interfaces.py:start():188] Started memory monitoring
2024-09-02 13:27:01,791 INFO    SystemMonitor:1886340 [interfaces.py:start():188] Started network monitoring
2024-09-02 13:27:01,835 DEBUG   HandlerThread:1886340 [system_info.py:probe():152] Probing system
2024-09-02 13:27:01,838 DEBUG   HandlerThread:1886340 [system_info.py:_probe_git():137] Probing git
2024-09-02 13:27:01,846 DEBUG   HandlerThread:1886340 [system_info.py:_probe_git():145] Probing git done
2024-09-02 13:27:01,847 DEBUG   HandlerThread:1886340 [system_info.py:probe():200] Probing system done
2024-09-02 13:27:01,847 DEBUG   HandlerThread:1886340 [system_monitor.py:probe():223] {'os': 'Linux-6.5.8-custom-x86_64-with-glibc2.35', 'python': '3.10.14', 'heartbeatAt': '2024-09-02T05:27:01.835820', 'startedAt': '2024-09-02T05:27:00.064225', 'docker': None, 'cuda': None, 'args': ('--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-6', '--deepspeed', '/home/lby/llava_med/LLaVA-Med/llava/train/zero3.json', '--model_name_or_path', '/srv/lby/llava_med/llava-med-v1.5-mistral-7b', '--version', 'v1', '--data_path', '/home/lby/llava_med/LLaVA-Med/llava/sft_data/classify_mimic_file.json', '--image_folder', '/srv/lby/physionet.org/files/mimic-cxr-jpg/2.0.0/files', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/home/lby/llava_med/LLaVA-Med/llava/checkpoints/llava-version1', '--num_train_epochs', '1', '--per_device_train_batch_size', '4', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-6', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '2', '--lazy_preprocess', 'True', '--report_to', 'wandb'), 'state': 'running', 'program': '/home/lby/llava_med/LLaVA-Med/llava/train/train_mem.py', 'codePathLocal': 'train_mem.py', 'codePath': 'llava/train/train_mem.py', 'git': {'remote': 'https://github.com/microsoft/LLaVA-Med.git', 'commit': 'ce6cc507bb540fab453dec2def539856423e0f38'}, 'email': '2230232178@qq.com', 'root': '/home/lby/llava_med/LLaVA-Med', 'host': 'caregpt-server', 'username': 'lby', 'executable': '/home/lby/anaconda3/envs/llava-med/bin/python3.10', 'cpu_count': 64, 'cpu_count_logical': 128, 'cpu_freq': {'current': 952.5314687499998, 'min': 800.0, 'max': 3400.0}, 'cpu_freq_per_core': [{'current': 799.97, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.045, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.364, 'min': 800.0, 'max': 3400.0}, {'current': 800.272, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.043, 'min': 800.0, 'max': 3400.0}, {'current': 800.042, 'min': 800.0, 'max': 3400.0}, {'current': 799.454, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 2800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.311, 'min': 800.0, 'max': 3400.0}, {'current': 799.95, 'min': 800.0, 'max': 3400.0}, {'current': 800.134, 'min': 800.0, 'max': 3400.0}, {'current': 799.64, 'min': 800.0, 'max': 3400.0}, {'current': 799.861, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.844, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.064, 'min': 800.0, 'max': 3400.0}, {'current': 799.76, 'min': 800.0, 'max': 3400.0}, {'current': 799.921, 'min': 800.0, 'max': 3400.0}, {'current': 799.817, 'min': 800.0, 'max': 3400.0}, {'current': 800.278, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.857, 'min': 800.0, 'max': 3400.0}, {'current': 799.89, 'min': 800.0, 'max': 3400.0}, {'current': 800.075, 'min': 800.0, 'max': 3400.0}, {'current': 799.945, 'min': 800.0, 'max': 3400.0}, {'current': 1239.103, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 874.095, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 1113.905, 'min': 800.0, 'max': 3400.0}, {'current': 2200.474, 'min': 800.0, 'max': 3400.0}, {'current': 2203.536, 'min': 800.0, 'max': 3400.0}, {'current': 2970.457, 'min': 800.0, 'max': 3400.0}, {'current': 1146.016, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 1600.172, 'min': 800.0, 'max': 3400.0}, {'current': 799.965, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.752, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.023, 'min': 800.0, 'max': 3400.0}, {'current': 799.779, 'min': 800.0, 'max': 3400.0}, {'current': 800.181, 'min': 800.0, 'max': 3400.0}, {'current': 799.715, 'min': 800.0, 'max': 3400.0}, {'current': 2203.013, 'min': 800.0, 'max': 3400.0}, {'current': 1720.694, 'min': 800.0, 'max': 3400.0}, {'current': 891.659, 'min': 800.0, 'max': 3400.0}, {'current': 800.249, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.886, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.047, 'min': 800.0, 'max': 3400.0}, {'current': 800.028, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.191, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.857, 'min': 800.0, 'max': 3400.0}, {'current': 799.776, 'min': 800.0, 'max': 3400.0}, {'current': 799.702, 'min': 800.0, 'max': 3400.0}, {'current': 799.732, 'min': 800.0, 'max': 3400.0}, {'current': 799.895, 'min': 800.0, 'max': 3400.0}, {'current': 800.602, 'min': 800.0, 'max': 3400.0}, {'current': 799.629, 'min': 800.0, 'max': 3400.0}, {'current': 799.877, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.854, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.64, 'min': 800.0, 'max': 3400.0}, {'current': 801.016, 'min': 800.0, 'max': 3400.0}, {'current': 799.826, 'min': 800.0, 'max': 3400.0}, {'current': 799.9, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.95, 'min': 800.0, 'max': 3400.0}, {'current': 799.892, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.86, 'min': 800.0, 'max': 3400.0}, {'current': 800.046, 'min': 800.0, 'max': 3400.0}, {'current': 800.181, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.864, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.045, 'min': 800.0, 'max': 3400.0}, {'current': 2200.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.967, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 2200.0, 'min': 800.0, 'max': 3400.0}, {'current': 2204.751, 'min': 800.0, 'max': 3400.0}, {'current': 820.363, 'min': 800.0, 'max': 3400.0}, {'current': 2799.992, 'min': 800.0, 'max': 3400.0}, {'current': 1045.002, 'min': 800.0, 'max': 3400.0}, {'current': 800.142, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 1600.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.781, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 798.081, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.148, 'min': 800.0, 'max': 3400.0}, {'current': 800.041, 'min': 800.0, 'max': 3400.0}, {'current': 800.146, 'min': 800.0, 'max': 3400.0}, {'current': 2200.159, 'min': 800.0, 'max': 3400.0}, {'current': 1978.746, 'min': 800.0, 'max': 3400.0}, {'current': 900.0, 'min': 800.0, 'max': 3400.0}, {'current': 799.842, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}, {'current': 800.0, 'min': 800.0, 'max': 3400.0}], 'disk': {'/': {'total': 877.5496253967285, 'used': 797.2865371704102}}, 'gpu': 'NVIDIA GeForce RTX 4090', 'gpu_count': 2, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 4090', 'memory_total': 25757220864}, {'name': 'NVIDIA GeForce RTX 4090', 'memory_total': 25757220864}], 'memory': {'total': 503.50914001464844}}
2024-09-02 13:27:01,847 INFO    HandlerThread:1886340 [system_monitor.py:probe():224] Finished collecting system info
2024-09-02 13:27:01,847 INFO    HandlerThread:1886340 [system_monitor.py:probe():227] Publishing system info
2024-09-02 13:27:01,847 DEBUG   HandlerThread:1886340 [system_info.py:_save_conda():209] Saving list of conda packages installed into the current environment
2024-09-02 13:27:01,952 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_created():271] file/dir created: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/conda-environment.yaml
2024-09-02 13:27:04,952 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/conda-environment.yaml
2024-09-02 13:27:05,017 DEBUG   HandlerThread:1886340 [system_info.py:_save_conda():224] Saving conda packages done
2024-09-02 13:27:05,020 INFO    HandlerThread:1886340 [system_monitor.py:probe():229] Finished publishing system info
2024-09-02 13:27:05,024 DEBUG   SenderThread:1886340 [sender.py:send():391] send: files
2024-09-02 13:27:05,025 INFO    SenderThread:1886340 [sender.py:_save_file():1466] saving file wandb-metadata.json with policy now
2024-09-02 13:27:05,230 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: python_packages
2024-09-02 13:27:05,231 DEBUG   SenderThread:1886340 [sender.py:send_request():418] send_request: python_packages
2024-09-02 13:27:05,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: stop_status
2024-09-02 13:27:05,232 DEBUG   SenderThread:1886340 [sender.py:send():391] send: telemetry
2024-09-02 13:27:05,233 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: status_report
2024-09-02 13:27:05,233 DEBUG   SenderThread:1886340 [sender.py:send_request():418] send_request: stop_status
2024-09-02 13:27:05,238 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:05,952 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_created():271] file/dir created: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/wandb-metadata.json
2024-09-02 13:27:05,953 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_created():271] file/dir created: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/requirements.txt
2024-09-02 13:27:06,022 DEBUG   SenderThread:1886340 [sender.py:send():391] send: config
2024-09-02 13:27:06,024 DEBUG   SenderThread:1886340 [sender.py:send():391] send: telemetry
2024-09-02 13:27:06,025 DEBUG   SenderThread:1886340 [sender.py:send():391] send: metric
2024-09-02 13:27:06,025 DEBUG   SenderThread:1886340 [sender.py:send():391] send: telemetry
2024-09-02 13:27:06,025 DEBUG   SenderThread:1886340 [sender.py:send():391] send: metric
2024-09-02 13:27:06,025 WARNING SenderThread:1886340 [sender.py:send_metric():1417] Seen metric with glob (shouldn't happen)
2024-09-02 13:27:06,025 DEBUG   SenderThread:1886340 [sender.py:send():391] send: telemetry
2024-09-02 13:27:06,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:06,580 INFO    wandb-upload_0:1886340 [upload_job.py:push():130] Uploaded file /tmp/tmptgi0fxurwandb/dj26xol0-wandb-metadata.json
2024-09-02 13:27:06,953 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_created():271] file/dir created: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/output.log
2024-09-02 13:27:07,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:08,120 WARNING FileStreamThread:1886340 [file_stream.py:request_with_retry():674] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/fly_win/huggingface/g5j2l05q/file_stream (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)'))). func: <bound method Session.post of <requests.sessions.Session object at 0x7f5385bb6590>>, args: ('https://api.wandb.ai/files/fly_win/huggingface/g5j2l05q/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 0, 'content': ['ERROR 2024-09-02T05:27:08.031762   0%|                                                                                  | 0/28816 [00:00<?, ?it/s]/home/lby/anaconda3/envs/llava-med/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n', 'ERROR 2024-09-02T05:27:08.031762   return fn(*args, **kwargs)\n', 'ERROR 2024-09-02T05:27:08.031762 /home/lby/anaconda3/envs/llava-med/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n', 'ERROR 2024-09-02T05:27:08.031762   warnings.warn(\n']}}, 'dropped': 0}}
2024-09-02 13:27:08,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:08,954 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/output.log
2024-09-02 13:27:09,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:10,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:10,955 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/output.log
2024-09-02 13:27:11,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: status_report
2024-09-02 13:27:11,233 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:11,786 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: partial_history
2024-09-02 13:27:11,790 DEBUG   SenderThread:1886340 [sender.py:send():391] send: metric
2024-09-02 13:27:11,790 DEBUG   SenderThread:1886340 [sender.py:send():391] send: metric
2024-09-02 13:27:11,791 DEBUG   SenderThread:1886340 [sender.py:send():391] send: metric
2024-09-02 13:27:11,791 DEBUG   SenderThread:1886340 [sender.py:send():391] send: history
2024-09-02 13:27:11,791 DEBUG   SenderThread:1886340 [sender.py:send_request():418] send_request: summary_record
2024-09-02 13:27:11,792 INFO    SenderThread:1886340 [sender.py:_save_file():1466] saving file wandb-summary.json with policy end
2024-09-02 13:27:11,955 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_created():271] file/dir created: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/wandb-summary.json
2024-09-02 13:27:12,233 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:13,233 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:13,956 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/output.log
2024-09-02 13:27:14,233 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
2024-09-02 13:27:14,957 INFO    Thread-12 :1886340 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/lby/llava_med/LLaVA-Med/llava/train/wandb/run-20240902_132700-g5j2l05q/files/output.log
2024-09-02 13:27:15,232 DEBUG   HandlerThread:1886340 [handler.py:handle_request():158] handle_request: internal_messages
