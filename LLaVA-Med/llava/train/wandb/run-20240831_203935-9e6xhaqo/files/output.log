
  0%|                                                                              | 0/7204 [00:00<?, ?it/s]/home/lby/anaconda3/envs/llava-med/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/lby/anaconda3/envs/llava-med/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Traceback (most recent call last):
  File "/home/lby/llava_med/LLaVA-Med/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/lby/llava_med/LLaVA-Med/llava/train/train.py", line 969, in train
    trainer.train()
  File "/home/lby/anaconda3/envs/llava-med/lib/python3.10/site-packages/transformers/trainer.py", line 1537, in train